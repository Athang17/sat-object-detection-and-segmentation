{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015501,
     "end_time": "2023-08-20T09:37:09.975481",
     "exception": false,
     "start_time": "2023-08-20T09:37:09.95998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Clean, reformat and re-size the xView dataset for object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:30.490074Z",
     "iopub.status.busy": "2023-10-07T20:26:30.489694Z",
     "iopub.status.idle": "2023-10-07T20:26:30.825258Z",
     "shell.execute_reply": "2023-10-07T20:26:30.823848Z",
     "shell.execute_reply.started": "2023-10-07T20:26:30.490029Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.258781,
     "end_time": "2023-08-20T09:37:10.250093",
     "exception": false,
     "start_time": "2023-08-20T09:37:09.991312",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os import sep\n",
    "import shutil\n",
    "import json\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import concurrent.futures\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015503,
     "end_time": "2023-08-20T09:37:10.281371",
     "exception": false,
     "start_time": "2023-08-20T09:37:10.265868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:30.828184Z",
     "iopub.status.busy": "2023-10-07T20:26:30.82736Z",
     "iopub.status.idle": "2023-10-07T20:26:30.843543Z",
     "shell.execute_reply": "2023-10-07T20:26:30.842137Z",
     "shell.execute_reply.started": "2023-10-07T20:26:30.828141Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034866,
     "end_time": "2023-08-20T09:37:10.331386",
     "exception": false,
     "start_time": "2023-08-20T09:37:10.29652",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Data sources\n",
    "DATA_FLDR_NM = 'Data'\n",
    "IN_DATASET_NM = 'xview-dataset'\n",
    "IMAGE_FLDR_NM = 'train_images'\n",
    "IN_LABELS_FLDR_NM = 'train_labels'\n",
    "LABELS_XML_NM = 'xView_train.geojson'\n",
    "\n",
    "#Output folders and file names\n",
    "OUT_DATASET_NM = 'xview-yolo-dataset'\n",
    "CLASS_MAP_JSON_NM = 'xView_class_map.json'\n",
    "OUT_COCO_JSON_NM = 'COCO_annotations.json'\n",
    "OUT_IMAGE_FLDR_NM = 'images'\n",
    "OUT_CFG_FLDR_NM = 'YOLO_cfg'\n",
    "OUT_DATAFRAME_NM = 'xview_labels.parquet'\n",
    "YAML_NM = 'xview_yolo.yaml'\n",
    "CHUNK_WIDTH = 640  # width of the images being created\n",
    "CHUNK_HEIGHT = 640\n",
    "MIN_CHUNK_HEIGHT = 320 # no images will be kept if the image chunk is smaller than this\n",
    "MIN_CHUNK_WIDTH = 320\n",
    "IMAGE_WRITING = True #True to re-perform image cropping, False just to regenerated other data\n",
    "TEST_FRACTION = 0.1\n",
    "JPEG_COMPRESSION = 95 # For the saved files\n",
    "VAL_FRACTION = 0.1\n",
    "RANDOM_SEED = 2023\n",
    "DEBUG = False\n",
    "\n",
    "in_kaggle = os.environ.get('PWD') == '/kaggle/working'\n",
    "if in_kaggle:\n",
    "    in_dataset_pth = Path('/kaggle/input/xview-dataset')\n",
    "    out_dataset_pth = Path('/kaggle/working/')\n",
    "    future_ds_img_fldr = Path(f'/kaggle/input/{OUT_DATASET_NM}/{OUT_IMAGE_FLDR_NM}')\n",
    "    future_ds_cfg_fldr = Path(f'/kaggle/input/{OUT_DATASET_NM}/{OUT_CFG_FLDR_NM}')\n",
    "else:\n",
    "    in_dataset_pth = Path(\"your/path/to/where/you/put/original/dataset\")\n",
    "    #in_dataset_pth = Path.cwd().parent / DATA_FLDR_NM / IN_DATASET_NM  #or put it here\n",
    "    out_dataset_pth = Path.cwd().parent / DATA_FLDR_NM / OUT_DATASET_NM  #change to suit\n",
    "    future_ds_img_fldr = out_dataset_pth / DATA_FLDR_NM / OUT_DATASET_NM / OUT_IMAGE_FLDR_NM\n",
    "    future_ds_cfg_fldr = out_dataset_pth / DATA_FLDR_NM /OUT_DATASET_NM / OUT_CFG_FLDR_NM \n",
    "\n",
    "labels_json_pth = in_dataset_pth / IN_LABELS_FLDR_NM / LABELS_XML_NM\n",
    "img_fldr_pth = in_dataset_pth / IMAGE_FLDR_NM / IMAGE_FLDR_NM\n",
    "save_images_fldr_pth = out_dataset_pth / OUT_IMAGE_FLDR_NM \n",
    "out_data_parquet_pth = out_dataset_pth / OUT_DATAFRAME_NM\n",
    "out_json_map_pth = out_dataset_pth / CLASS_MAP_JSON_NM \n",
    "class_map_pth = out_dataset_pth / CLASS_MAP_JSON_NM\n",
    "cfg_fldr_pth = out_dataset_pth / OUT_CFG_FLDR_NM\n",
    "coco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\n",
    "yolo_yaml_pth = cfg_fldr_pth / YAML_NM\n",
    "train_txt_pth = cfg_fldr_pth / 'train.txt'\n",
    "val_txt_pth = cfg_fldr_pth / 'train.txt'\n",
    "test_txt_pth = cfg_fldr_pth / 'test.txt'\n",
    "\n",
    "def make_empty_dir(directory):\n",
    "    if directory.is_dir():\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "make_empty_dir(cfg_fldr_pth)\n",
    "if IMAGE_WRITING:\n",
    "    make_empty_dir(save_images_fldr_pth)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f'The input images are found at {cfg_fldr_pth}')\n",
    "print(f'The input labels are found at  {labels_json_pth}')\n",
    "print(f'Configuration files will be saved to {cfg_fldr_pth}')\n",
    "print(f'YOLO image files will be saved to {save_images_fldr_pth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0148,
     "end_time": "2023-08-20T09:37:10.361381",
     "exception": false,
     "start_time": "2023-08-20T09:37:10.346581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:30.845475Z",
     "iopub.status.busy": "2023-10-07T20:26:30.845173Z",
     "iopub.status.idle": "2023-10-07T20:26:30.874544Z",
     "shell.execute_reply": "2023-10-07T20:26:30.873343Z",
     "shell.execute_reply.started": "2023-10-07T20:26:30.84545Z"
    },
    "papermill": {
     "duration": 0.05672,
     "end_time": "2023-08-20T09:37:10.463018",
     "exception": false,
     "start_time": "2023-08-20T09:37:10.406298",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_boxes(in_df, class_lst=[]):\n",
    "    if class_lst:\n",
    "        in_df = in_df[in_df['TYPE_ID'].isin(class_lst)]\n",
    "    unique_images = in_df.IMAGE_ID.unique().tolist()\n",
    "    boxs = {}\n",
    "\n",
    "    for image in tqdm_notebook(unique_images):\n",
    "        mask = in_df['IMAGE_ID'] == image\n",
    "        masked = in_df[mask][['TYPE_ID', 'XMIN', 'YMIN', 'XMAX', 'YMAX']]\n",
    "        boxs[image] = masked.values.tolist()\n",
    "    return boxs\n",
    "\n",
    "\n",
    "def print_first_n_lines(file_path, n):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line_num, line in enumerate(file, 1):\n",
    "                if line_num > n:\n",
    "                    break\n",
    "                print(line.strip())\n",
    "    except FileNotFoundError:\n",
    "        print('Unable to open file')\n",
    "\n",
    "\n",
    "def load_image(file_pth): #for display\n",
    "    image_obj = cv2.imread(file_pth)\n",
    "    image_obj = cv2.cvtColor(image_obj, cv2.COLOR_BGR2RGB)\n",
    "    return image_obj\n",
    "\n",
    "\n",
    "def load_bgr_image(file_pth): # for processing only, no need to visualise the image\n",
    "    image_obj = cv2.imread(file_pth)\n",
    "    return image_obj\n",
    "\n",
    "'''The colors are displaying a bit odd intermittently on Ubuntu.  I haven't got to the bottom of why, but suspect it has\n",
    "something to do with the pixel depth.  Shouldn't actually matter for the purpose of making the training dataset.\n",
    "'''\n",
    "def display_images(image_lst, boxes_dictionary, image_fldr, max_images=6, no_cols=1, text=False,  class_map={}):\n",
    "    total_ims = len(image_lst)\n",
    "    display_ims = min(max_images, total_ims)\n",
    "    no_rows = display_ims//no_cols + (display_ims % no_cols > 0)\n",
    "    fig, axs = plt.subplots(no_rows, no_cols, figsize=(10, 10*no_rows/no_cols*3/4))\n",
    "    axs = axs.flatten()\n",
    "    for k, img_nm in enumerate(image_lst[:display_ims]):\n",
    "        image_path = str(image_fldr / img_nm)\n",
    "        img = load_image(image_path)\n",
    "\n",
    "        # create a bounding box with the data & draw it\n",
    "        if img_nm in boxes_dictionary:\n",
    "            for box in boxes_dictionary[img_nm]:\n",
    "                box_id, x_min, y_min, x_max, y_max = box\n",
    "                x_min, y_min, x_max, y_max = int(x_min), int(y_max), int(x_max), int(y_min)\n",
    "                # (left top), (right, bottom) == (XMIN, YMIN), (XMAX, YMAX)\n",
    "                cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0,255,0), 3)\n",
    "                if text:\n",
    "                    if class_map:\n",
    "                        box_label = class_map[box_id]\n",
    "                    else:\n",
    "                        box_label = str(box_id)\n",
    "                    cv2.putText(img, box_label, (x_min, y_max-10), cv2.FONT_HERSHEY_SIMPLEX, 2, (36,255,12), 4)\n",
    "\n",
    "        # Show image with bboxes\n",
    "        axs[k].set_title(f\"Image {img_nm}\", fontsize = 12)\n",
    "        axs[k].imshow(img)\n",
    "        axs[k].set_axis_off()\n",
    "\n",
    "    # Display all the images\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "#Convert YOLO to CV2 rectangle (l,t),(r,b)\n",
    "def get_corners(x_cen, y_cen, an_width, an_height, im_width, im_height):\n",
    "    x_cen, y_cen, an_width, an_height = float(x_cen), float(y_cen), float(an_width), float(an_height)\n",
    "    left = (x_cen - an_width/2)*im_width\n",
    "    top = (y_cen - an_height/2)*im_height\n",
    "    right = (x_cen + an_width/2)*im_width\n",
    "    bottom = (y_cen + an_height/2)*im_height\n",
    "    return int(left), int(top), int(right), int(bottom)\n",
    "\n",
    "\n",
    "def display_yolo_images(image_lst, image_fldr, max_images=6, no_cols=1, text=False,  class_map={}):\n",
    "    total_ims = len(image_lst)\n",
    "    display_ims = min(max_images, total_ims)\n",
    "    no_rows = display_ims//no_cols + (display_ims % no_cols > 0)\n",
    "    _, axs = plt.subplots(no_rows, no_cols, figsize=(10, 10*no_rows/no_cols*3/4))\n",
    "    axs = axs.flatten()\n",
    "    for k, img_nm in enumerate(image_lst[:display_ims]):\n",
    "        image_path = image_fldr / img_nm\n",
    "        text_fn = image_path.stem + '.txt'\n",
    "        boxes_path = image_fldr / text_fn\n",
    "        img = load_image(str(image_path))\n",
    "        im_h, im_w, _ = img.shape\n",
    "        with open(boxes_path) as text_file:\n",
    "            annotations = [line.rstrip().split() for line in text_file]\n",
    "\n",
    "        # create a bounding box with the data & draw it\n",
    "        for ann in annotations:\n",
    "                class_id = ann[0]\n",
    "                x_centre, y_centre, w, h = ann[1], ann[2], ann[3], ann[4]\n",
    "                x_min, y_min, x_max, y_max = get_corners(x_centre, y_centre, w, h, im_w, im_h)\n",
    "                # (left top), (right bottom) == (XMIN, YMIN), (XMAX, YMAX)\n",
    "                cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0,255,0), 3)\n",
    "                if text:\n",
    "                    if class_map:\n",
    "                        box_label = class_map[int(class_id)]\n",
    "                    else:\n",
    "                        box_label = str(class_id)\n",
    "                    cv2.putText(img, box_label, (x_min, y_max-10), cv2.FONT_HERSHEY_SIMPLEX, 2, (36,255,12), 4)\n",
    "\n",
    "        # Show image with bboxes\n",
    "        axs[k].set_title(f\"Image {img_nm}\", fontsize = 12)\n",
    "        axs[k].imshow(img)\n",
    "        axs[k].set_axis_off()\n",
    "\n",
    "    # Display all the images\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "# For a given square within a chunk of a larger image, find any boxes in it\n",
    "# Return the boxes in YOLO format relative to the chunk boundary\n",
    "def match_boxes(box_list, chnk_lims):\n",
    "    boxes_lists = []\n",
    "    le, to = chnk_lims[0], chnk_lims[1]  # chunk_limits = [c, r, chunk_w, chunk_h]\n",
    "    w, h  = chnk_lims[2], chnk_lims[3]\n",
    "    for box in box_list:\n",
    "        o_left, o_top, o_right, o_bottom = box[1], box[2], box[3], box[4]\n",
    "        left, right = (o_left - le)/w, (o_right - le)/w  # translate and normalise\n",
    "        top, bottom = (o_top - to)/h, (o_bottom - to)/h\n",
    "\n",
    "        h_match = (0 <= left < 1) or (0 < right <= 1)\n",
    "        v_match = (0 <= top < 1) or (0 < bottom <= 1)\n",
    "\n",
    "        if v_match and h_match:\n",
    "            clipped = np.clip([left, top, right, bottom], a_min=0, a_max=1)\n",
    "            l, t, r, b = clipped[0], clipped[1], clipped[2], clipped[3]\n",
    "            bounding_box = [str(box[0]),\n",
    "                            str(round((l + r)/2, 5)),\n",
    "                            str(round((t + b)/2, 5)),\n",
    "                            str(round(r-l, 5)),\n",
    "                            str(round(b-t, 5))]\n",
    "            boxes_lists.append(bounding_box)\n",
    "    return boxes_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:30.877777Z",
     "iopub.status.busy": "2023-10-07T20:26:30.877349Z",
     "iopub.status.idle": "2023-10-07T20:26:49.866788Z",
     "shell.execute_reply": "2023-10-07T20:26:49.865758Z",
     "shell.execute_reply.started": "2023-10-07T20:26:30.877739Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 21.245452,
     "end_time": "2023-08-20T09:37:31.724333",
     "exception": false,
     "start_time": "2023-08-20T09:37:10.478881",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(labels_json_pth, 'r') as infile:\n",
    "    data = json.load(infile)\n",
    "    keys = list(data.keys())\n",
    "\n",
    "feature_list = data['features']\n",
    "COLUMNS = ['IMAGE_ID', 'TYPE_ID', 'XMIN', 'YMIN', 'XMAX', 'YMAX', 'LONG', 'LAT']\n",
    "\n",
    "data = []\n",
    "for feature in tqdm_notebook(feature_list):\n",
    "    properties = feature['properties'] # a dict\n",
    "    img_id = properties['image_id']  # '389.tif'\n",
    "    type_id = properties['type_id']\n",
    "    bbox = properties['bounds_imcoords'].split(\",\")  # eg '1917,38,1958,64'\n",
    "    geometry = feature ['geometry']\n",
    "    coords = geometry['coordinates'][0] #for some reason it's a list of lists\n",
    "    long = coords[0][0] / 2  + coords[2][0] / 2\n",
    "    lat = coords[0][1] / 2  + coords[1][1] / 2\n",
    "    one_row = [img_id, type_id, bbox[0], bbox[1], bbox[2], bbox[3], long, lat]\n",
    "    data.append(one_row)\n",
    "\n",
    "instances = len(data)\n",
    "print(f'There are {instances} object instances in the original dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015391,
     "end_time": "2023-08-20T09:37:31.755149",
     "exception": false,
     "start_time": "2023-08-20T09:37:31.739758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Extracting the columns of interest only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:49.86836Z",
     "iopub.status.busy": "2023-10-07T20:26:49.86803Z",
     "iopub.status.idle": "2023-10-07T20:26:52.314457Z",
     "shell.execute_reply": "2023-10-07T20:26:52.313551Z",
     "shell.execute_reply.started": "2023-10-07T20:26:49.868334Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.979887,
     "end_time": "2023-08-20T09:37:35.750799",
     "exception": false,
     "start_time": "2023-08-20T09:37:31.770912",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns = COLUMNS)\n",
    "df[['XMIN', 'YMIN', 'XMAX', 'YMAX']] = df[['XMIN', 'YMIN', 'XMAX', 'YMAX']].apply(pd.to_numeric)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015796,
     "end_time": "2023-08-20T09:37:35.782811",
     "exception": false,
     "start_time": "2023-08-20T09:37:35.767015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Removing two erroneous annotation class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:52.316004Z",
     "iopub.status.busy": "2023-10-07T20:26:52.315725Z",
     "iopub.status.idle": "2023-10-07T20:26:52.38503Z",
     "shell.execute_reply": "2023-10-07T20:26:52.383887Z",
     "shell.execute_reply.started": "2023-10-07T20:26:52.31598Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.090876,
     "end_time": "2023-08-20T09:37:35.889334",
     "exception": false,
     "start_time": "2023-08-20T09:37:35.798458",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df[(df.TYPE_ID != 75) & (df.TYPE_ID != 82)]   # removing erroneous labels\n",
    "print(f'{instances - len(df)} rows removed, leaving {len(df)} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:52.386879Z",
     "iopub.status.busy": "2023-10-07T20:26:52.386345Z",
     "iopub.status.idle": "2023-10-07T20:26:52.398437Z",
     "shell.execute_reply": "2023-10-07T20:26:52.397483Z",
     "shell.execute_reply.started": "2023-10-07T20:26:52.386845Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.033242,
     "end_time": "2023-08-20T09:37:35.938148",
     "exception": false,
     "start_time": "2023-08-20T09:37:35.904906",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015627,
     "end_time": "2023-08-20T09:37:35.969758",
     "exception": false,
     "start_time": "2023-08-20T09:37:35.954131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Also removing anything from image 1395, this image does not exist in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:52.400012Z",
     "iopub.status.busy": "2023-10-07T20:26:52.399669Z",
     "iopub.status.idle": "2023-10-07T20:26:52.547612Z",
     "shell.execute_reply": "2023-10-07T20:26:52.546485Z",
     "shell.execute_reply.started": "2023-10-07T20:26:52.399986Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.206868,
     "end_time": "2023-08-20T09:37:36.192499",
     "exception": false,
     "start_time": "2023-08-20T09:37:35.985631",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "old_length = len(df)\n",
    "df = df[df.IMAGE_ID != '1395.tif']\n",
    "print(f'{old_length - len(df)} rows removed, leaving {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017306,
     "end_time": "2023-08-20T09:37:36.22665",
     "exception": false,
     "start_time": "2023-08-20T09:37:36.209344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Also it's useful to convert the type IDs into a continuous sequence from 0 to 59 for the 60 categories.  The original competition labels were not arranged this way. The dictionary below is the original mapping from the competition website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:52.549425Z",
     "iopub.status.busy": "2023-10-07T20:26:52.549007Z",
     "iopub.status.idle": "2023-10-07T20:26:52.558261Z",
     "shell.execute_reply": "2023-10-07T20:26:52.557115Z",
     "shell.execute_reply.started": "2023-10-07T20:26:52.549389Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.032082,
     "end_time": "2023-08-20T09:37:36.275789",
     "exception": false,
     "start_time": "2023-08-20T09:37:36.243707",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "old_dict = {\n",
    "    11:'Fixed-wing Aircraft', 12:'Small Aircraft', 13:'Passenger/Cargo Plane', 15:'Helicopter',\n",
    "    17:'Passenger Vehicle', 18:'Small Car', 19:'Bus', 20:'Pickup Truck', 21:'Utility Truck',\n",
    "    23:'Truck', 24:'Cargo Truck', 25:'Truck Tractor w/ Box Trailer', 26:'Truck Tractor',27:'Trailer',\n",
    "    28:'Truck Tractor w/ Flatbed Trailer', 29:'Truck Tractor w/ Liquid Tank', 32:'Crane Truck',\n",
    "    33:'Railway Vehicle', 34:'Passenger Car', 35:'Cargo/Container Car', 36:'Flat Car', 37:'Tank car',\n",
    "    38:'Locomotive', 40:'Maritime Vessel', 41:'Motorboat', 42:'Sailboat', 44:'Tugboat', 45:'Barge',\n",
    "    47:'Fishing Vessel', 49:'Ferry', 50:'Yacht', 51:'Container Ship', 52:'Oil Tanker',\n",
    "    53:'Engineering Vehicle', 54:'Tower crane', 55:'Container Crane', 56:'Reach Stacker',\n",
    "    57:'Straddle Carrier', 59:'Mobile Crane', 60:'Dump Truck', 61:'Haul Truck', 62:'Scraper/Tractor',\n",
    "    63:'Front loader/Bulldozer', 64:'Excavator', 65:'Cement Mixer', 66:'Ground Grader', 71:'Hut/Tent',\n",
    "    72:'Shed', 73:'Building', 74:'Aircraft Hangar', 76:'Damaged Building', 77:'Facility', 79:'Construction Site',\n",
    "    83:'Vehicle Lot', 84:'Helipad', 86:'Storage Tank', 89:'Shipping container lot', 91:'Shipping Container',\n",
    "    93:'Pylon', 94:'Tower'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016868,
     "end_time": "2023-08-20T09:37:36.309336",
     "exception": false,
     "start_time": "2023-08-20T09:37:36.292468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Making a new mapping from 0 to 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:52.563146Z",
     "iopub.status.busy": "2023-10-07T20:26:52.562802Z",
     "iopub.status.idle": "2023-10-07T20:26:52.582797Z",
     "shell.execute_reply": "2023-10-07T20:26:52.581668Z",
     "shell.execute_reply.started": "2023-10-07T20:26:52.563112Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028567,
     "end_time": "2023-08-20T09:37:36.356101",
     "exception": false,
     "start_time": "2023-08-20T09:37:36.327534",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "old_keys = sorted(list(old_dict.keys()))\n",
    "new_dict = {old_dict[x]:y for y, x in enumerate(old_keys)}\n",
    "class_map_dict = {y:old_dict[x] for y, x in enumerate(old_keys)}\n",
    "with open(out_json_map_pth, \"w\") as json_file:\n",
    "    json.dump(class_map_dict, json_file)\n",
    "print(class_map_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016279,
     "end_time": "2023-08-20T09:37:36.388677",
     "exception": false,
     "start_time": "2023-08-20T09:37:36.372398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can convert the dataframe's old TYPE_IDs to their new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:52.585316Z",
     "iopub.status.busy": "2023-10-07T20:26:52.584851Z",
     "iopub.status.idle": "2023-10-07T20:26:52.845893Z",
     "shell.execute_reply": "2023-10-07T20:26:52.84509Z",
     "shell.execute_reply.started": "2023-10-07T20:26:52.585284Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.53075,
     "end_time": "2023-08-20T09:37:36.936733",
     "exception": false,
     "start_time": "2023-08-20T09:37:36.405983",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['TYPE_ID'] = df['TYPE_ID'].apply(lambda x: new_dict[old_dict[x]])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017037,
     "end_time": "2023-08-20T09:37:36.971734",
     "exception": false,
     "start_time": "2023-08-20T09:37:36.954697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Just to check the data is loading sensibly, I'm displaying a couple of images with any transport related annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-07T20:26:52.847442Z",
     "iopub.status.busy": "2023-10-07T20:26:52.847086Z",
     "iopub.status.idle": "2023-10-07T20:27:26.445375Z",
     "shell.execute_reply": "2023-10-07T20:27:26.444349Z",
     "shell.execute_reply.started": "2023-10-07T20:26:52.847417Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 50.051776,
     "end_time": "2023-08-20T09:38:27.040083",
     "exception": false,
     "start_time": "2023-08-20T09:37:36.988307",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_classes = list(class_map_dict.keys())\n",
    "transport_only = [x for x in all_classes if x < 48]\n",
    "\n",
    "boxes = get_boxes(df, transport_only)\n",
    "images_for_display = random.choices(list(boxes.keys()), k=2)\n",
    "display_images(images_for_display, boxes, img_fldr_pth, max_images=2, no_cols=2, text=True, class_map=class_map_dict) #adjust as desired"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1561333,
     "sourceId": 2571636,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30527,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
